# 问题种类：regression 、 classification 、 structuredLearning
$$
y = w * x + b (linear)
$$
* 训练合适的w和b
## 定义loss函数：
* MAE： regression中预测值与label之间差的绝对值和
* MSE： regression中预测值与label之间差的平方和
* Cross-Entropy：classification中预测值与label的交叉熵
## training：找到loss最小的feature
## optimize
* 通常使用梯度下降法：对各个feature求偏导得到梯度，向梯度减小的方向修改参数
* tips：对于斜率变化小的case，在梯度下降的过程中使用相同的步长将很难达到最优的loss。通常使用adam(pytorch自带)、冲量梯度下降法来优化

# DNN

上述linear的方程没法预测更多一般的情况，通常采用多个ReLU函数或者Sigmoid函数来逼近真实的分布
### sigmoid
$$y = b + \sum_i c_i sigmoid(y_j)$$
上式$y_j$也可以写成$y_j = b + \sum_j w_jx_j $
有$$y = b + \sum_i c_i sigmoid(b_i + \sum_j w_{ij}x_i)$$
写成矩阵形式
$$
 y = b + \begin{bmatrix} c\end{bmatrix}^T + sigmoid(b + \begin{bmatrix} W\end{bmatrix}\begin{bmatrix} x\end{bmatrix})
$$
* 上式的$y$当作下一层的输入，又可以套一层神经网路，即是简单的DNN模型
### 批处理
训练时候将数据分成多个batch，每个batch计算出一个loss，根据loss来计算梯度，更新feature。
* 全部batch计算完称为一个epoch

# CNN
CNN通常用于图像操作，输入是一幅图像
## 卷积
对于输入图像看作一个矩阵$\begin{bmatrix} Image\end{bmatrix}$ , 定义一个卷积核矩阵$\begin{bmatrix} Filter\end{bmatrix}$与其上的数字相乘相加得到一个值称为一次卷积  
通过训练出一系列的卷积核一层一层的对图像进行卷积运算提取相关的特征

### 一些问题及解决
* 卷积没法超出边界导致卷积结果大小 < 原图大小 => 通过给图像边界补0（padding）
* 每次卷积都对整个图像操作，计算量大，参数多，容易overfitting => 设定Receptive Field
#### Receptive Field相关
针对不同的特征，课程中提到的“识别鸟”的任务，可以训练一些特征如鸟喙、鸟腿、翅膀。  
将输入图像划分成多个Receptive Field，每个Receptive Field由识别多种特征的神经元来检测。  
相同特征的神经元共享参数，检测不同的Receptive Field（某个特征可能出现在输入图像的不同位置，所以每个Receptive Field都要放检测某一特征的神经元）
#### 池化
有时候运算量过大时，可以使用池化减少运算量
* 池化挑选一次卷积的结果中的某一个值：最大值（max pooling） 最小值（min pooling） 平均值（mean pooling） 
* 但是减少运算量的同时会丢失精度

# self attention
$$
k = W_k * I
$$

$$
q = W_q * I
$$

$$
v = W_v * I
$$
计算第i个输入与第j个输入的相关性
$$
\alpha_{ij} = dot(q_i , k_j )
$$
得到相关性后，该层的输出
$$b_i = \sum_i \alpha_{ij} v_i$$
将得到的结果通过softmax操作得到一个结果的置信值
## multi-head self-attention
self-attention计算 q、k、v, multi-head将计算$q_1,q_2,k_1,k_2,v_1,v_2$  
计算相关性：
$$\alpha_{ijk} = dot(q_{ik} , k_{jk})$$
计算输出：
$$b_{ik} = \sum_i \alpha_{ijk} v_k$$
将得到的$b_i1 , b_i2$拼接：  
$$b_i = \begin{bmatrix} W_b\end{bmatrix} \begin{bmatrix} b_{i1}\\b_{i2}\end{bmatrix}$$
## positional encoding
给输入向量$I$加入位置信息
$$I + e^i$$

# Transformer : encoder + decoder
## encoder
$\begin{bmatrix} x_1 \\ x_2 \\...\\x_n\end{bmatrix}$=> block => $\begin{bmatrix} y_1 \\ y_2 \\...\\y_n\end{bmatrix}$  
### block
$\begin{bmatrix} x_1 \\ x_2 \\...\\x_n\end{bmatrix}$ => self-attention => $\begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$  
  
$\begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$ + $\begin{bmatrix} x_1 \\ x_2 \\...\\x_n\end{bmatrix}$ => norm
* norm :${ x - \mu \over \sigma}$

## decoder
获取encoder的输出作为输入，产生transformer真正的输出  
$\begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$ => decoder  
token => decoder  
特殊的输入：给decoder的token中有两个特殊的字符：BOS（begin of sequence）和END  
masked-self-attention：通常的self-attention每个输出都会看过所有的输入，masked-self-attention只会看之前的输入，不看之后的输入  
vocabulary-list：transformer输出的token组成的词典
### decoder过程： 
* 开始时获取encoder的输出结果，token使用BOS，经过masked-self-attention
* masked-self-attention的输出经过soft-max得到概率分布，选取最大的值对应的vocabulary-list的token作为decoder的输出
* 之后的轮次，将decoder每次的输出，累计作为新的输入再次输出，直到输出END为止
### 改进
使用这种方式是顺序串行产生结果，效率较低  
考虑并行化，NAT（non-autoregressive）：难点在于不确定输出的长度
* 1、另外训练一个神经网络，用于产生输出的长度N
* 2、给定一个最大值的输出数量，截取到END作为输出

## encoder和decoder的信息传递
encoder输出$\begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$  
参考self-attention的思想：
$$k = W_k \begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$$
$$v = W_v \begin{bmatrix} x_1' \\ x_2' \\...\\x_n'\end{bmatrix}$$
$$q = W_q \begin{bmatrix} token'\end{bmatrix}(token'是token经过masked-self-attention得到的向量)$$
最终输出$$b = \sum_i dot(k_i , q) * v_i$$

## 一些问题
* 1、串行输出的decoder在输出一个错误token后将会一步错，步步错  
ans：在训练时不用decoder的输出作为输入，而是使用ground truth作为输入
* 2、有时transformer会忽略输入的一部分或者获得了乱序的输入（语音识别时必须有序才有意义）  
ans：使用guided-attention，训练时强迫顺序看完训练资料

# TODO:
* 本地搭建环境跑几个神经网络（家里设备和网络都比较差，所以搭环境比较慢）
* 继续往下：GAN 、 self-supervised learning